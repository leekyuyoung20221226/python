{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526b7d00-3409-4af6-8520-9bd42b6981ec",
   "metadata": {},
   "source": [
    "# 토픽분석\n",
    "    - description 컬럼 추출\n",
    "     - 명사토큰추출 okt.nouns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2efc90ff-2c4a-42ff-8793-2884a71ee1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/leekyuyoung20221226/python/main/data/%EC%BD%94%EB%A1%9C%EB%82%98%20%EB%89%B4%EC%8A%A4.csv'\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d50e848d-5099-438d-9630-91faccfb9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(url)\n",
    "description = data_df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5069f571-fc2f-4b3c-ba87-3bb68fbf96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d49774-5920-4761-9926-584250d0c9e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "phrase input should be string, not <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m description_noun_tk \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m description:\n\u001b[1;32m----> 4\u001b[0m     description_noun_tk\u001b[38;5;241m.\u001b[39mappend(\u001b[43mokt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnouns\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py\\lib\\site-packages\\konlpy\\tag\\_okt.py:83\u001b[0m, in \u001b[0;36mOkt.nouns\u001b[1;34m(self, phrase)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnouns\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase):\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124;03m\"\"\"Noun extractor.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     tagged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [s \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m tagged \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py\\lib\\site-packages\\konlpy\\tag\\_okt.py:69\u001b[0m, in \u001b[0;36mOkt.pos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124;03m\"\"\"POS tagger.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    In contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    this POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    :param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mvalidate_phrase_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjki\u001b[38;5;241m.\u001b[39mtokenize(\n\u001b[0;32m     72\u001b[0m                 phrase,\n\u001b[0;32m     73\u001b[0m                 jpype\u001b[38;5;241m.\u001b[39mjava\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39mBoolean(norm),\n\u001b[0;32m     74\u001b[0m                 jpype\u001b[38;5;241m.\u001b[39mjava\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39mBoolean(stem))\u001b[38;5;241m.\u001b[39mtoArray()\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m join:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\py\\lib\\site-packages\\konlpy\\tag\\_common.py:20\u001b[0m, in \u001b[0;36mvalidate_phrase_inputs\u001b[1;34m(phrase)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"validate if phrase input is provided in str format\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    phrase (str): phrase input\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphrase input should be string, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(phrase)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(phrase, basestring), msg\n",
      "\u001b[1;31mAssertionError\u001b[0m: phrase input should be string, not <class 'float'>"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "description_noun_tk = []\n",
    "for d in description:\n",
    "    description_noun_tk.append(okt.nouns(d)) # 명사 형태소만 추출\n",
    "# 에러  : phrase input should be string, not <class 'float'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b97c92aa-e86a-4f61-994f-af7b564dafb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN은 파이썬에서 float 타입이다. 그래서 위에서 전처리를 안해서 에러가 발생했음\n",
    "type(data_df[data_df['description'].isnull()]['description'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6de38cb4-b4be-433a-bdbd-93189165c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad96a4ea-af2f-49e8-9d35-6657fbf7a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_noun_tk = []\n",
    "description = data_df['description']\n",
    "for d in description:\n",
    "    description_noun_tk.append(okt.nouns(d)) # 명사 형태소만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a896ba97-b8c5-4dec-bef6-49af1987c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  토큰의 길이가 1보다 큰 것만 추출\n",
    "description_noun_tk2 = []\n",
    "for d in description_noun_tk:\n",
    "     description_noun_tk2.append([i for i in d if len(i) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efd6af7c-d274-4bc1-a75c-79836df0779a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_noun_tk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ada1c-8312-482b-ae2e-e3ace732e608",
   "metadata": {},
   "source": [
    "# 토픽분석을 위한 LDA 모델 구축\n",
    "    gensim 라이브러리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcff65d6-cb1a-433b-9444-8e3951bb045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.0-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "     --------------------------------------- 24.0/24.0 MB 50.4 MB/s eta 0:00:00\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.8/56.8 kB ? eta 0:00:00\n",
      "Collecting Cython==0.29.32\n",
      "  Downloading Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n",
      "     ------------------------------------- 986.3/986.3 kB 30.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from gensim) (1.24.1)\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.1/67.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting simpful\n",
      "  Downloading simpful-2.9.0-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\py\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.13)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20431 sha256=fd01166ae2d0a34f3493d918ad8e48a840fec3577297c7c31daf2da4efb6f70b\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\01\\02\\ee\\df0699282986903a384b69aab4413af9efd26b3612b5dccc9e\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3514 sha256=124d749418e605cbc28e047c6b6be8f457b3c6e7b00ad968a3067bc03c387a6f\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\43\\aa\\48\\5c66b931ff013ad19774081aa19656637af5c0cc33b5494b30\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: smart-open, Cython, simpful, miniful, fst-pso, pyfume, FuzzyTM, gensim\n",
      "Successfully installed Cython-0.29.32 FuzzyTM-2.0.5 fst-pso-1.8.1 gensim-4.3.0 miniful-0.0.6 pyfume-0.2.25 simpful-2.9.0 smart-open-6.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8fa6461-dc46-44df-916e-fefdb5a19d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57567a2e-6d36-4333-904a-d888228834c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LDA 토픽모델의 입력 베터 생성\n",
    "dictionary =  corpora.Dictionary(description_noun_tk2)  # 사전 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8628c45-44f2-40c3-bd59-849c658ca4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'감염증'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[0]  # 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3eeccf0-9c3a-4c1e-a69f-9a80dc4143f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 뭉치를 구성\n",
    "corpus =  [dictionary.doc2bow(word) for word in description_noun_tk2]\n",
    "# print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2204a4a7-e556-4497-a93f-8e601746a4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 토픽의 개수를 설정 - 하이퍼 파라메터\n",
    "k = 2\n",
    "lda_model =  gensim.models.ldamulticore.LdaMulticore(corpus,iterations=12,num_topics=k, id2word = dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "61f23cee-50f9-4d04-8179-1d2d3ddd8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(gensim.models.ldamulticore.LdaMulticore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d08bfe5-3555-4547-a4e3-3b556d4330ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.093*\"코로나\" + 0.021*\"진자\" + 0.013*\"신규\" + 0.010*\"접종\" + 0.010*\"방역\" + 0.009*\"중국\" + 0.008*\"백신\" + 0.007*\"중앙\" + 0.007*\"발생\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.006*\"본부\" + 0.006*\"검사\" + 0.006*\"이후\" + 0.005*\"지난\"'), (1, '0.075*\"코로나\" + 0.021*\"진자\" + 0.011*\"중국\" + 0.011*\"방역\" + 0.010*\"신규\" + 0.010*\"발생\" + 0.009*\"접종\" + 0.008*\"검사\" + 0.008*\"백신\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.007*\"본부\" + 0.007*\"이후\" + 0.006*\"재난\" + 0.006*\"지난\"')]\n"
     ]
    }
   ],
   "source": [
    "# 토픽분석 결과 출력\n",
    "print(lda_model.print_topics(num_topics=k, num_words=15))\n",
    "# 토픽을 구성하는 주요  단어 15개가 토픽에 대한 영향력 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "42a2e073-db85-45d4-bf94-c7c220b0d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topics = lda_model.print_topics(num_topics=k, num_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e570d1d-0d18-4c03-8d61-a470b0c58816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lda_topics), len(lda_topics[0][1].split('+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0f9fdf7f-9d1d-4981-b07c-a1e1c5d81080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  d = {'col1': [1, 2], 'col2': [3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14de4b15-d99a-4ca0-bb14-fae06404d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1 = {}\n",
    "dic1['토픽번호'] = [i[0] for i in lda_topics]\n",
    "dic1['주요단어(15)'] = [i[1] for i in lda_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cdb5d6b9-743f-475e-8fe3-f916b4d489b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1d94505d-4909-4d71-b53a-d5490b25497c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토픽번호</th>\n",
       "      <th>주요단어(15)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093*\"코로나\" + 0.021*\"진자\" + 0.013*\"신규\" + 0.010*\"접종\" + 0.010*\"방역\" + 0.009*\"중국\" + 0.008*\"백신\" + 0.007*\"중앙\" + 0.007*\"발생\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.006*\"본부\" + 0.006*\"검사\" + 0.006*\"이후\" + 0.005*\"지난\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.075*\"코로나\" + 0.021*\"진자\" + 0.011*\"중국\" + 0.011*\"방역\" + 0.010*\"신규\" + 0.010*\"발생\" + 0.009*\"접종\" + 0.008*\"검사\" + 0.008*\"백신\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.007*\"본부\" + 0.007*\"이후\" + 0.006*\"재난\" + 0.006*\"지난\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   토픽번호  \\\n",
       "0     0   \n",
       "1     1   \n",
       "\n",
       "                                                                                                                                                                                            주요단어(15)  \n",
       "0  0.093*\"코로나\" + 0.021*\"진자\" + 0.013*\"신규\" + 0.010*\"접종\" + 0.010*\"방역\" + 0.009*\"중국\" + 0.008*\"백신\" + 0.007*\"중앙\" + 0.007*\"발생\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.006*\"본부\" + 0.006*\"검사\" + 0.006*\"이후\" + 0.005*\"지난\"  \n",
       "1  0.075*\"코로나\" + 0.021*\"진자\" + 0.011*\"중국\" + 0.011*\"방역\" + 0.010*\"신규\" + 0.010*\"발생\" + 0.009*\"접종\" + 0.008*\"검사\" + 0.008*\"백신\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.007*\"본부\" + 0.007*\"이후\" + 0.006*\"재난\" + 0.006*\"지난\"  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "30fcf766-3180-42eb-af97-332e2283ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1['토픽레이블'] = ['확진자 신규 접종 대책','확진자 중국 방역 대책']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f54decda-bbf1-478c-9576-c183893d4f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토픽번호</th>\n",
       "      <th>주요단어(15)</th>\n",
       "      <th>토픽레이블</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093*\"코로나\" + 0.021*\"진자\" + 0.013*\"신규\" + 0.010*\"접종\" + 0.010*\"방역\" + 0.009*\"중국\" + 0.008*\"백신\" + 0.007*\"중앙\" + 0.007*\"발생\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.006*\"본부\" + 0.006*\"검사\" + 0.006*\"이후\" + 0.005*\"지난\"</td>\n",
       "      <td>확진자 신규 접종 대책</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.075*\"코로나\" + 0.021*\"진자\" + 0.011*\"중국\" + 0.011*\"방역\" + 0.010*\"신규\" + 0.010*\"발생\" + 0.009*\"접종\" + 0.008*\"검사\" + 0.008*\"백신\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.007*\"본부\" + 0.007*\"이후\" + 0.006*\"재난\" + 0.006*\"지난\"</td>\n",
       "      <td>확진자 중국 방역 대책</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   토픽번호  \\\n",
       "0     0   \n",
       "1     1   \n",
       "\n",
       "                                                                                                                                                                                            주요단어(15)  \\\n",
       "0  0.093*\"코로나\" + 0.021*\"진자\" + 0.013*\"신규\" + 0.010*\"접종\" + 0.010*\"방역\" + 0.009*\"중국\" + 0.008*\"백신\" + 0.007*\"중앙\" + 0.007*\"발생\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.006*\"본부\" + 0.006*\"검사\" + 0.006*\"이후\" + 0.005*\"지난\"   \n",
       "1  0.075*\"코로나\" + 0.021*\"진자\" + 0.011*\"중국\" + 0.011*\"방역\" + 0.010*\"신규\" + 0.010*\"발생\" + 0.009*\"접종\" + 0.008*\"검사\" + 0.008*\"백신\" + 0.007*\"대책\" + 0.007*\"기준\" + 0.007*\"본부\" + 0.007*\"이후\" + 0.006*\"재난\" + 0.006*\"지난\"   \n",
       "\n",
       "          토픽레이블  \n",
       "0  확진자 신규 접종 대책  \n",
       "1  확진자 중국 방역 대책  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dic1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58233bb-7ded-4323-b55c-ae0af0b75f26",
   "metadata": {},
   "source": [
    "# 분석결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99257b35-0d2e-44dc-83e0-4f68914a1586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
