{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0ofC6a8j-f34"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 VGG-16 모델 읽어오기\n",
        "net = models.vgg16(pretrained = True)\n",
        "net.eval() # 추론(평가) 모드로  설정 - 드랍아웃 및 배치 정규화를 평가 모드로 설정..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lulb_1HB-rId",
        "outputId": "a8698acf-10e8-4d0c-bbe3-41c51f30c7b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "# PIL  (높이,너비,채널)  파이토치(채널,높이,너비)\n",
        "class BaseTransform():\n",
        "  def __init__(self,resize,mean,std):\n",
        "    self.base_transform = transforms.Compose([\n",
        "        transforms.Resize(resize), # 짧은 변의 길이가 resize가 되도록 만든다.\n",
        "        transforms.CenterCrop(resize),  # 화면 중앙을 resize x resize로 자른다\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean,std)  # 색상정보를 표준화\n",
        "    ])\n",
        "  def __call__(self,img):    \n",
        "    return self.base_transform(img)"
      ],
      "metadata": {
        "id": "4-ZiAh_T_QK8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg-16 1000차원 출력을 라벨명으로 변환 ILSVRPredictor 클래스를\n",
        "# json 파일\n",
        "import json\n",
        "ILSVRC_class_index =  json.load(open('./imagenet_class_index.json','r'))"
      ],
      "metadata": {
        "id": "T7fyCFctGGAK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력 결과에서 라벨을 예측하는 클래스\n",
        "class ILSVRCPredictor():\n",
        "  def __init__(self,class_index):\n",
        "    self.class_index = class_index\n",
        "  def predict_max(self, out):\n",
        "    # 최대확률의 라벨명을 가져온다\n",
        "    maxid = np.argmax(out.detach().numpy())  # 출력 값을 네트웍에서 분리\n",
        "    predicted_label_name = self.class_index[str(maxid)][1]\n",
        "    return predicted_label_name"
      ],
      "metadata": {
        "id": "dQeJO8D_Gf4h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 읽어오기\n",
        "resize=224\n",
        "mean,std = (0.5,0.5,0.5),(0.2,0.2,0.2)\n",
        "img_path = '/content/다운로드.jpg'\n",
        "img = Image.open(img_path)\n",
        "transform = BaseTransform(resize,mean,std)\n",
        "img_transformed = transform(img)\n",
        "print(img_transformed.shape)\n",
        "inputs = img_transformed.unsqueeze(0)\n",
        "inputs.shape"
      ],
      "metadata": {
        "id": "-G2EcRV5H6GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = net(inputs)\n",
        "predictor = ILSVRCPredictor(ILSVRC_class_index)\n",
        "result = predictor.predict_max(out)\n",
        "result"
      ],
      "metadata": {
        "id": "O5oB9LyrLMQn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}