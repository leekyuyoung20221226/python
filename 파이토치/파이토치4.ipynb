{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keEoWDvCUL2y",
        "outputId": "f28ed6f4-2a8b-49e1-e868-7a557f7b9401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "epoch:0 loss:1.7447677850723267\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self,in_channels, out_channels, hidden_dim) -> None:\n",
        "    super(BasicBlock,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels,hidden_dim,kernel_size=3,padding=1)\n",
        "    self.conv2 = nn.Conv2d(hidden_dim,out_channels,kernel_size=3,padding=1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    return x\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self,num_classes) -> None:\n",
        "    super(CNN,self).__init__()\n",
        "    self.block1 = BasicBlock(in_channels=3,out_channels=32,hidden_dim=16)\n",
        "    self.block2 = BasicBlock(in_channels=32,out_channels=128,hidden_dim=64)\n",
        "    self.block3 = BasicBlock(in_channels=128,out_channels=256,hidden_dim=128)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=4096,out_features=2048)\n",
        "    self.fc2 = nn.Linear(in_features=2048,out_features=256)\n",
        "    self.fc3 = nn.Linear(in_features=256,out_features=num_classes)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = torch.flatten(x,start_dim=1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "from torchvision.transforms import Normalize\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomCrop\n",
        "from torchvision.transforms.transforms import Compose\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.adam import Adam\n",
        "import torchvision.transforms as T\n",
        "transforms = Compose([\n",
        "    # T.ToPILImage(),\n",
        "    RandomCrop((32,32),padding=4),\n",
        "    RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    Normalize(mean =(0.49139968, 0.48215827, 0.44653124), std=(0.24703233, 0.24348505, 0.26158768) ),    \n",
        "])\n",
        "# 0.49139968, 0.48215827, 0.44653124, 0.24703233, 0.24348505, 0.26158768    \n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "train_data = CIFAR10(root=\"./\", train=True,download=True, transform =transforms)\n",
        "test_data = CIFAR10(root=\"./\", train=False,download=True, transform =transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(test_data,batch_size=32,shuffle=False)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CNN(10)\n",
        "model.to(device)\n",
        "lr = 0.0001\n",
        "optim = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for data,label in train_loader:\n",
        "    optim.zero_grad()\n",
        "    preds = model(data.to(device))    \n",
        "    loss = nn.CrossEntropyLoss()(preds,label.to(device))    \n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch:{epoch} loss:{loss}\")\n",
        "torch.save(model.state_dict(), 'CIFAR.pth')    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가하기\n",
        "num_corr = 0\n",
        "with torch.no_grad():\n",
        "  for data, label in test_loader:\n",
        "    output = model(data.to(device))\n",
        "    preds = output.data.max(1)[1]\n",
        "    corr = preds.eq(label.to(device).data).sum().item()\n",
        "    num_corr += corr\n",
        "\n",
        "num_corr / len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4qpLgJ4g7j7",
        "outputId": "6b0f8bff-0704-414d-ecfc-fb51567c5f5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7244"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZbOYst-oi_uy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}