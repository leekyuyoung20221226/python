{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rz2IMDw_d-nV"
      },
      "outputs": [],
      "source": [
        "# GAN : 적대적 생성 신경망 + CNN   DCGAN\n",
        "# 생성모델(G)  식별모델 D\n",
        "# G : k차원의 잠재적 특이 벡터를 입력값으로 받아서 대상과 동일형식의 데이터를 생셩하는 신경망\n",
        "# D : 대상데이터를 입력값으로 받아 진위를식별하는 신경망"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN\n",
        "# 1. 잠재적 특이 벡터 z를 난수로  생성하고 G(z)를 사용해 가짜 데이터(fake data)를 생성  fake_data <-- G(z)\n",
        "# 2. fake_data를 D로식별한다  fake_data<-- D(real_data)\n",
        "# 3. 진짜 데이터의 샘플(real_data)을 D로  식별한다  real_out<--- D(real_data)\n",
        "# 4. fake_out 이 진짜 데이터라고 간주하고 크로스 엔트로피함수를 계산해서 G의 파라메터를  갱신\n",
        "# 5. real_out이 진짜 데이터이고 fake_out이 가짜 데이터라고 간주하고 크로스 엔트로피 함수를 계산해서 D의 파라메터를 갱신"
      ],
      "metadata": {
        "id": "O9_Mi5Jdek4m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
        "!tar -zxvf 102flowers.tgz"
      ],
      "metadata": {
        "id": "RTUUbVWCfZ_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir oxford-102\n",
        "!mkdir oxford-102/jpg\n",
        "!mv jpg/*.jpg oxford-102/jpg"
      ],
      "metadata": {
        "id": "KhKK7aAHf-Qh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rmdir jpg"
      ],
      "metadata": {
        "id": "9rpzF66QgL45"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "cV-_6x4ogVQL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_data = ImageFolder('/content/oxford-102',\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Resize(80),\n",
        "                           transforms.CenterCrop(64),\n",
        "                           transforms.ToTensor()\n",
        "                       ])\n",
        "                       )\n",
        "batch_size = 64\n",
        "img_loader = DataLoader(img_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "NE8sOceEjonx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data,label = next(iter(img_loader))"
      ],
      "metadata": {
        "id": "9zG72oO3kU8B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.shape, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdorHeTIkYN_",
        "outputId": "8df480b1-f1c2-4e94-b5b9-eb327add690e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 3, 64, 64]),\n",
              " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 잠재적 특이 벡터 z를 100차원으로 만든, z  3 x 64 x 64 의 이미지를 만드는 생성모델을 구축\n",
        "# ConvTransposed2d\n",
        "nz = 100\n",
        "ngf = 32\n",
        "class GNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GNet, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.ConvTranspose2d(nz, ngf*8, 4,1,0,bias=False  ), # 출력값에 편항을 추가하지 않아서 더 간단한 모델을 구현\n",
        "        nn.BatchNorm2d(ngf*8),\n",
        "        nn.ReLU(inplace=True), # 출력값을 새로운 변수에 할당하지 않고 기존의 변수에 덮어쓴다.  메모리 사용량을 줄인다\n",
        "        \n",
        "        nn.ConvTranspose2d(ngf*8, ngf*4, 4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ngf*4),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf*4, ngf*2, 4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ngf*2),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf*2, ngf, 4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ngf),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(ngf, 3, 4,2,1,bias=False),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.main(x)"
      ],
      "metadata": {
        "id": "7gxz_XUJklhv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 식별모델은 3 x 64 x 64 이미지를 최종적으로 1차원 스칼라로 변환하는 신경망\n",
        "# 원래 논문에서 선형 계층을 사용하지 않음\n",
        "\n",
        "ndf = 32\n",
        "class DNet(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super(DNet,self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Conv2d(3,ndf, 4,2,1,bias=False),\n",
        "        nn.LeakyReLU(0.2,inplace=True),       \n",
        "\n",
        "        nn.Conv2d(ndf,ndf*2, 4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ndf*2),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(ndf*2,ndf*4, 4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ndf*4),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(ndf*4,ndf*8, 4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(ndf*8),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "        nn.Conv2d(ndf*8,1, 4,2,1,bias=False)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.main(x).squeeze()"
      ],
      "metadata": {
        "id": "Gjcth08KoAml"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5번 합성곱 연산을해서 3 x 64 x64 이미지가 최종적으로 1 x 1x 1이 된다. \n",
        "# A x 1 x B x1 불필요한 1이 들어있는 shape를 A x B 처럼 조정\n",
        "# Conv2d 는 입력과 출력 모두(batch_size, channel, height, width)  -- (batch_size,1,1,1)--> 불필요한 차원을 삭제"
      ],
      "metadata": {
        "id": "MBFbQp3ApmSt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "d = DNet().to(device)\n",
        "g = GNet().to(device)"
      ],
      "metadata": {
        "id": "YJkt292SqNhz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DCGAN 원 논문에 기술되어 있는 파라메터 값\n",
        "out_d = optim.Adam(d.parameters(), lr = 0.0002,betas=(0.5,0.999))\n",
        "out_g = optim.Adam(g.parameters(), lr = 0.0002,betas=(0.5,0.999))\n",
        "\n",
        "# 크로스 엔트로피를 계산하기 위한 보조 변수\n",
        "ones = torch.ones(batch_size).to(device)\n",
        "zeros = torch.zeros(batch_size).to(device)\n",
        "loss_f = nn.BCEWithLogitsLoss()  # 출력값을 logit으로 변환하여 시그모이들 함수를 적용한다음 binary cross entropy손실을 계산\n",
        "# logit : 0.5를 임계치로 삼아서. 양성 음성 클래스 변환\n",
        "# 로짓함수의 수식은 : logit(p) = log(p / (1 - p))   p는 0과 1사이의 확률\n",
        "\n",
        "# 모니터링용 Z\n",
        "fixed_z = torch.randn(batch_size, nz,1,1).to(device)"
      ],
      "metadata": {
        "id": "Qf8WTOQnqqUD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8l6culpYs09k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}