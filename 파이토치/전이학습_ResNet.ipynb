{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ResNet \n",
        "# 스킵 커넥션을 사용해서 VGG에 비해 훨씬 많은 층을 쌓는다\n",
        "# nn.Module을 이용해서 신경망 내부의 데이터 흐름을 제어한다.\n",
        "# 기울기 소실 : 은닉층이 깊어지면 입력층에 가까운 가중치들의 기울기가 0에 가까워지는 현상\n",
        "# 배치 정규화 : 배치간의 차이를 정규화... 더 안정되게 학습\n",
        "# 스킵 커넥션 : 은닉층을 거치지 않은 입력값과 은닉층의 결과를 더하는 구조"
      ],
      "metadata": {
        "id": "EfWNTl4jXwzt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zPEEUxalXoGb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self,in_channels, out_channels, kernel_size=3) -> None:\n",
        "    super(BasicBlock, self).__init__()\n",
        "    # 합성곱 정의\n",
        "    self.c1 = nn.Conv2d(in_channels,out_channels,kernel_size=kernel_size,padding=1)\n",
        "    self.c2 = nn.Conv2d(out_channels,out_channels,kernel_size=kernel_size,padding=1)\n",
        "    self.downsample = nn.Conv2d(in_channels,out_channels,kernel_size=1) # 스킵커넥션을 위해서 입력과 출력의 채널 개수를 맞춤\n",
        "    # 배치정규화\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x_ = x  # 스킵커넥션을 위해 초기 입력 저장\n",
        "\n",
        "    x = self.c1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.c2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    # 합성곱의 결과와 입력의 채널 수를 맞춤\n",
        "    x_ = self.downsample(x_)\n",
        "\n",
        "    x += x_  # 합성곱층의 결과와 저장했던 입력값을 더함(스킵 커넥션)\n",
        "    x = self.relu(x)    \n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 ->[기본블럭 평균폴링] -> [기본블럭 평균폴링]->[기본블럭 평균폴링] ->평탄화 ->분류기 ->출력\n",
        "# 32x32 이미지가 4x4 가 될대까지 반복\n",
        "# 32*32(입력) ->기본블럭(평균폴링)(16)->기본블럭(평균폴링)(8)->기본블럭(평균폴링)(4)\n",
        "# 블럭을 3번"
      ],
      "metadata": {
        "id": "ayXospX7bCwF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self,num_classes=10) -> None:\n",
        "    super(ResNet,self).__init__()\n",
        "    # 기본블럭\n",
        "    self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
        "    self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
        "    self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
        "\n",
        "    # 폴링은 평균폴링, 평균값은 폴링의 커널안에 포함된 모든 픽셀의 정보를 담고있어서 맥스보다는 유리함\n",
        "    self.pool = nn.AvgPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    #분류기\n",
        "    self.fc1 = nn.Linear(in_features=256*4*4, out_features=2048)\n",
        "    self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
        "    self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self, x):\n",
        "    x = self.b1(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.b2(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.b3(x)\n",
        "    x = self.pool(x)\n",
        "    x = torch.flatten(x,start_dim=1)  # 평탄화\n",
        "    # 분류기로 값을 예측\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc3(x)  \n",
        "    return x  "
      ],
      "metadata": {
        "id": "jBL79SFBc1E0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "# 라이브러리 로드\n",
        "import tqdm\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torchvision.transforms import RandomHorizontalFlip,RandomCrop,Normalize\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.adam import Adam"
      ],
      "metadata": {
        "id": "9YFjC04leJcC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_data = CIFAR10(root = './', train=True, download=True, transform=ToTensor)\n",
        "# rgb_m = training_data.data.mean(axis=(0,1,2)) / 255\n",
        "# rgb_s = training_data.data.std(axis=(0,1,2)) / 255\n",
        "# rgb_m, rgb_s"
      ],
      "metadata": {
        "id": "WfN_5NRueLYD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = Compose([    \n",
        "    RandomCrop((32,32),padding=4),\n",
        "    RandomHorizontalFlip(p=0.5),\n",
        "    ToTensor(),    \n",
        "    Normalize(mean = (0.49139968, 0.48215841, 0.44653091), std=(0.24703223, 0.24348513, 0.26158784) )\n",
        "])"
      ],
      "metadata": {
        "id": "9jub96wKfKb6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더정의\n",
        "training_data = CIFAR10(root = './', train=True, download=True, transform=transforms)\n",
        "test_data = CIFAR10(root = './', train=False, download=True, transform=transforms)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=64,shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iglF8U2PfOui",
        "outputId": "42ca835b-a7a6-44da-8846-b2ab8d3afd7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "model = ResNet(num_classes=10)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQsiNWFNfThB",
        "outputId": "f75a3204-1011-42b2-dcd9-7d5eff1a393b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (b1): BasicBlock(\n",
              "    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (b2): BasicBlock(\n",
              "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (b3): BasicBlock(\n",
              "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b = next(iter(train_loader))\n",
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N77J4Y2ciBLK",
        "outputId": "933e1f7d-4874-482a-e61a-ec2a33610e63"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = 1e-4\n",
        "# optim = Adam(model.parameters(), lr=lr)\n",
        "# data, label = next(iter(train_loader))\n",
        "# optim.zero_grad()\n",
        "# preds = model(data.to(device))\n",
        "# loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "# loss.backward()\n",
        "# optim.step()"
      ],
      "metadata": {
        "id": "ZY_aq_HJk7JZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프 정의\n",
        "lr = 1e-4\n",
        "optim = Adam(model.parameters(), lr=lr)\n",
        "for epoch in range(30):\n",
        "  it = tqdm.tqdm(train_loader)\n",
        "  for data, label in it:    \n",
        "    optim.zero_grad()\n",
        "    preds = model(data.to(device))\n",
        "    loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    \n",
        "    it.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCs0kMN8fi4Z",
        "outputId": "b0cb7900-001e-45f7-9e9b-bef0159bedd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:1 loss:1.0946922302246094: 100%|██████████| 782/782 [00:45<00:00, 17.36it/s]\n",
            "epoch:2 loss:1.149419903755188: 100%|██████████| 782/782 [00:44<00:00, 17.77it/s]\n",
            "epoch:3 loss:0.8546673059463501: 100%|██████████| 782/782 [00:43<00:00, 17.95it/s]\n",
            "epoch:4 loss:0.6087036728858948: 100%|██████████| 782/782 [00:44<00:00, 17.66it/s]\n",
            "epoch:5 loss:0.4584844708442688: 100%|██████████| 782/782 [00:44<00:00, 17.67it/s]\n",
            "epoch:6 loss:0.23697921633720398: 100%|██████████| 782/782 [00:44<00:00, 17.63it/s]\n",
            "epoch:7 loss:0.37208831310272217: 100%|██████████| 782/782 [00:44<00:00, 17.71it/s]\n",
            "epoch:8 loss:0.6237072944641113: 100%|██████████| 782/782 [00:44<00:00, 17.77it/s]\n",
            "epoch:9 loss:0.21885251998901367: 100%|██████████| 782/782 [00:44<00:00, 17.49it/s]\n",
            "epoch:10 loss:0.2856753468513489: 100%|██████████| 782/782 [00:44<00:00, 17.68it/s]\n",
            "epoch:11 loss:0.7609376907348633: 100%|██████████| 782/782 [00:44<00:00, 17.72it/s]\n",
            "epoch:12 loss:0.23405851423740387: 100%|██████████| 782/782 [00:43<00:00, 17.79it/s]\n",
            "epoch:13 loss:0.3794228434562683: 100%|██████████| 782/782 [00:44<00:00, 17.69it/s]\n",
            "epoch:14 loss:0.2735975682735443: 100%|██████████| 782/782 [00:44<00:00, 17.52it/s]\n",
            "epoch:15 loss:0.3819229006767273: 100%|██████████| 782/782 [00:44<00:00, 17.74it/s]\n",
            "epoch:16 loss:0.22807477414608002: 100%|██████████| 782/782 [00:43<00:00, 17.98it/s]\n",
            "epoch:17 loss:0.18327054381370544: 100%|██████████| 782/782 [00:43<00:00, 17.97it/s]\n",
            "epoch:18 loss:0.17542992532253265: 100%|██████████| 782/782 [00:44<00:00, 17.76it/s]\n",
            "epoch:19 loss:0.07589587569236755: 100%|██████████| 782/782 [00:44<00:00, 17.54it/s]\n",
            "epoch:20 loss:0.5539355874061584: 100%|██████████| 782/782 [00:44<00:00, 17.75it/s]\n",
            "epoch:21 loss:0.25304514169692993:  23%|██▎       | 179/782 [00:10<00:40, 14.71it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"/content/drive/MyDrive/Colab Notebooks/CIFAR10_ResNet.pth\")"
      ],
      "metadata": {
        "id": "oiPHJmauf1oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/CIFAR10_ResNet.pth',map_location = device))\n",
        "num_corr = 0\n",
        "with torch.no_grad():\n",
        "  for data, label in test_loader:\n",
        "    output = model(data.to(device))\n",
        "    preds = output.data.max(1)[1]\n",
        "    corr = preds.eq(label.to(device).data).sum().item()\n",
        "    num_corr  += corr\n",
        "print(f\"accuracy : {num_corr / len(test_data)}\")    "
      ],
      "metadata": {
        "id": "463rM4O3opSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjqFgOFFo2C9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}